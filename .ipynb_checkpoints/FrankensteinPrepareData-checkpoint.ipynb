{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e022571-c00e-4526-8aa5-31180c259dc3",
   "metadata": {},
   "source": [
    "CREATE DATASET sur un corpus de test  sur le corpus téléchargé de projet guttenberg.J'ai d'abord installé le librarie nltk qui contiens le corpus gutenberg ainsi que le stopwords etc. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caebb01b-70ba-45b2-8a2e-09ccd2efb148",
   "metadata": {},
   "source": [
    "IMPORT PACKAGES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a95d007-6b07-4495-8268-295ba53f63b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import tokenize\n",
    "import numpy as np\n",
    "import random\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "622d0bc5-9eec-4836-8472-7051f3450402",
   "metadata": {},
   "source": [
    "LOAD DATA AND CREATE COMBINED DATASET"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "032a6828-5b72-4af7-9a36-5ddc6d5deb39",
   "metadata": {},
   "source": [
    "In creating the sentence lists, we exclude sentences of less than 5 characters in length, as these are unlikely to be proper sentences and are likely too short to contain any useful information. As the sentence tokenizer has difficulties in identifying the end of sentences under some circumstances (e.g. if the full-stop at the end of the sentence is contained within quotation marks), we make some minor adjustments to the text prior to tokenization using the replace function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "66ca09d7-ee93-4704-b2b1-491c75ed30da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_text(filepath, min_char):\n",
    "    \"\"\"Convert text file to a list of sentences.\n",
    "    \n",
    "    Args:\n",
    "    filepath: string. Filepath of text file.\n",
    "    min_char: int. Minimum number of characters required for a sentence to be\n",
    "    included.\n",
    "\n",
    "    Returns:\n",
    "    sentences: list of strings. List of sentences containined in the text file.\n",
    "    \"\"\"\n",
    "    # Load data into string variable and remove new line characters\n",
    "    file = open(filepath, \"r\", encoding=\"utf8\")\n",
    "    text = file.read().replace('\\n', ' ')\n",
    "    text = text.replace('.”', '”.').replace('.\"', '\".').replace('?”', '”?').replace('!”', '”!')\n",
    "    text = text.replace('--', ' ').replace('. . .', '').replace('_', '')\n",
    "    file.close()\n",
    "    \n",
    "    # Split text into a list of sentences\n",
    "    sentences = tokenize.sent_tokenize(text)\n",
    "    \n",
    "    # Remove sentences that are less than min_char long\n",
    "    sentences = [sent for sent in sentences if len(sent) >= min_char]\n",
    "\n",
    "    return list(sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "144504af-c39d-433e-8c43-3c99174bfc03",
   "metadata": {},
   "source": [
    "CREATE SENTENCE LIST FOR EACH AUTHOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "73f3ba86-d9e2-4ed8-bd25-bcb2e74410e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set parameter values\n",
    "min_char = 5\n",
    "\n",
    "# Create lists\n",
    "frankenstein = split_text('Books/frankenstein.txt', min_char = min_char)\n",
    "lastMan = split_text('Books/LastMan.txt', min_char = min_char)\n",
    "\n",
    "books = frankenstein + lastMan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "60ac773d-2059-4e67-84ca-672bbfec9e42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frankenstein : 3266\n",
      "Last Man : 6938\n"
     ]
    }
   ],
   "source": [
    "# Print length of each list\n",
    "\n",
    "text_dict = {'Frankenstein': frankenstein, 'Last Man': lastMan }\n",
    "\n",
    "\n",
    "for key in text_dict.keys():\n",
    "    print(key, ':', len(text_dict[key]))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ef3371e-0a46-46f1-8039-ecf14f1ad462",
   "metadata": {},
   "source": [
    "All lists contain between 8641 and 14414 sentences. So that our final dataset doesn't become skewed towards a single author, we will randomly select 8500 sentences from each list (without replacement) to form the final dataset.\n",
    "\n",
    "Select and combine sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "de8cd445-78f8-4ab1-8473-3c1897dbe833",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of the combined list is: 1000\n"
     ]
    }
   ],
   "source": [
    "# Set random seed\n",
    "np.random.seed(1)\n",
    "\n",
    "# Set length parameter\n",
    "max_len = 500\n",
    "\n",
    "# Select sentences\n",
    "names = [frankenstein,lastMan]\n",
    "combined = []\n",
    "\n",
    "for name in names:\n",
    "    name = np.random.choice(name, max_len, replace = False)\n",
    "    combined += list(name)\n",
    "\n",
    "print('The length of the combined list is:', len(combined))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46999381-afaf-4652-98a4-b25c9bebf55d",
   "metadata": {},
   "source": [
    "Create labels list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "6fc8689c-1837-40d9-8921-68061d0f6474",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of the labels list is: 1000\n"
     ]
    }
   ],
   "source": [
    "labels = ['Frankenstein']*max_len + ['LastMan']*max_len\n",
    "\n",
    "print('The length of the labels list is:', len(labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7cb2914-d0fd-469e-8ce7-e71f74785523",
   "metadata": {},
   "source": [
    "Randomly sort data\n",
    "\n",
    "We randomly shuffle the data to avoid any issues arising from the bunching together of sentences by a single author."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b41c8012-c25f-46e9-92f4-9e1e823f9dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed\n",
    "random.seed(3)\n",
    "\n",
    "# Randomly shuffle data\n",
    "zipped = list(zip(combined, labels,))\n",
    "random.shuffle(zipped)\n",
    "combined, labels  = zip(*zipped)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ca56d7e-93bc-4063-8d92-5e98e6cad7fc",
   "metadata": {},
   "source": [
    "Create and export final dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "3475fcf0-18b4-4f0b-9978-b2bace594e16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text          book\n",
      "0  Our situation was somewhat dangerous, especial...  Frankenstein\n",
      "1                        “Get well—and return to us.       LastMan\n",
      "2  I had hitherto supposed him to be the murderer...  Frankenstein\n",
      "3  Human being there was none to reply; and the i...  Frankenstein\n",
      "4  If for one instant I had thought what might be...       LastMan\n"
     ]
    }
   ],
   "source": [
    "# Create pandas dataframe\n",
    "out_data = pd.DataFrame()\n",
    "out_data['text'] = combined\n",
    "out_data['book'] = labels\n",
    "\n",
    "print(out_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "e4fff683-b4c8-4003-87cf-f36aa3ceda93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export as a csv file\n",
    "out_data.to_csv('shelley_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc47f15e-f4f1-41df-93e1-18ca4d5be1df",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
